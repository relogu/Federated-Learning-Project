{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46132/926046215.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlorotUniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from functools import partial\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "# from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from scipy.spatial.distance import cdist\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as dtf\n",
    "from datashader.mpl_ext import dsshow\n",
    "\n",
    "# Make TensorFlow log less verbose\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import RandomNormal, GlorotUniform\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.losses import kl_divergence\n",
    "\n",
    "import umap\n",
    "import hdbscan\n",
    "from mdutils.mdutils import MdUtils\n",
    "\n",
    "#FLP_path = pathlib.Path('/home/relogu/Desktop/OneDrive/UNIBO/Magistrale/Federated Learning Project').absolute()\n",
    "FLP_path = pathlib.Path('/home/STUDENTI/lorenzo.sani/Federated-Learning-Project').absolute()\n",
    "sys.path.insert(1, str(FLP_path))\n",
    "\n",
    "from py.losses import get_keras_loss\n",
    "from py.dec.util import create_denoising_autoencoder, create_clustering_model, target_distribution\n",
    "import py.metrics as my_metrics\n",
    "from py.util import compute_centroid_np, get_dims_from_weights\n",
    "\n",
    "#results_path = pathlib.Path('/home/relogu/Desktop/OneDrive/UNIBO/Magistrale/Federated Learning Project/bmnist_adam_glorotiuninit/output_bmnist1')\n",
    "results_path = pathlib.Path('/home/STUDENTI/lorenzo.sani/Federated-Learning-Project/bmnist_sgd_glorotuninit/output_bmnist1')\n",
    "N_CLUSTERS = 10\n",
    "LOSS = 'bce'\n",
    "\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.set_visible_devices(gpus[2], 'GPU')\n",
    "# disable possible gpu devices for this kernel\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix = 'aggregated_weights_'\n",
    "encoder_param = np.load(results_path/str('encoder.npz'),\n",
    "                        allow_pickle=True)\n",
    "encoder_param = np.squeeze(np.array([encoder_param[p] for p in encoder_param]))\n",
    "encoder_ft_param = np.load(results_path/str('encoder_ft.npz'),\n",
    "                           allow_pickle=True)\n",
    "encoder_ft_param = np.squeeze(np.array([encoder_ft_param[p] for p in encoder_ft_param]))\n",
    "encoder_final_param = np.load(results_path/str('encoder_final.npz'),\n",
    "                              allow_pickle=True)\n",
    "encoder_final_param = np.squeeze(np.array([encoder_final_param[p] for p in encoder_final_param]))\n",
    "initial_centroids = np.load(results_path/'initial_centroids.npz',\n",
    "                            allow_pickle=True)\n",
    "initial_centroids = np.squeeze(np.array([initial_centroids[p] for p in initial_centroids]))\n",
    "final_centroids = np.load(results_path/str('final_centroids.npz'),\n",
    "                          allow_pickle=True)\n",
    "final_centroids = np.squeeze(np.array([final_centroids[p] for p in final_centroids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initial Centroids: {}'.format(initial_centroids))\n",
    "print('Final Centroids: {}'.format(final_centroids))\n",
    "delta_centroids = final_centroids-initial_centroids\n",
    "print('Delta Centroids: {}'.format(delta_centroids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "n_features = int(x_train.shape[1]*x_train.shape[1])\n",
    "x_train, x_test = np.round(x_train.reshape(x_train.shape[0], n_features)/255), np.round(x_test.reshape(x_test.shape[0], n_features)/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the autoencoder\n",
    "dims = get_dims_from_weights(encoder_param)\n",
    "config = {\n",
    "    'batch_size': 256,\n",
    "    'n_clusters': 10,\n",
    "    'kmeans_n_init': 20,\n",
    "    'ae_epochs': 50000,\n",
    "    'ae_optimizer': SGD(\n",
    "        learning_rate=0.1,\n",
    "        momentum=0.9,\n",
    "        decay=(0.1-0.0001)/50000),\n",
    "    # 'ae_optimizer': Adam(),\n",
    "    'ae_dims': dims,\n",
    "    'ae_act': 'relu',\n",
    "    # 'ae_init': RandomNormal(mean=0.0,\n",
    "    #                         stddev=0.01),\n",
    "    'ae_init': GlorotUniform(seed=51550),\n",
    "    'is_tied': True,\n",
    "    'u_norm_reg': False,\n",
    "    'ortho_w_con': False,\n",
    "    'uncoll_feat_reg': False,\n",
    "    'use_bias': True,\n",
    "    'dropout_rate': 0.0,\n",
    "    'noise_rate': 0.0,\n",
    "    'ran_flip_conf': None,\n",
    "    'ae_metrics': [\n",
    "        my_metrics.rounded_accuracy,\n",
    "    ],\n",
    "    'cl_optimizer': SGD(\n",
    "        learning_rate=0.01,\n",
    "        momentum=0.9),\n",
    "    'update_interval': 160,\n",
    "    'ae_loss': get_keras_loss(LOSS),\n",
    "    'cl_loss': 'kld',\n",
    "    'seed': 51550}\n",
    "\n",
    "autoencoder, encoder, decoder = create_denoising_autoencoder(\n",
    "    flavor='real',\n",
    "    dims=config['ae_dims'],\n",
    "    activation=config['ae_act'],\n",
    "    w_init=config['ae_init'],\n",
    "    is_tied=config['is_tied'],\n",
    "    u_norm_reg=config['u_norm_reg'],\n",
    "    ortho_w_con=config['ortho_w_con'],\n",
    "    uncoll_feat_reg=config['uncoll_feat_reg'],\n",
    "    use_bias=config['use_bias'],\n",
    "    dropout_rate=config['dropout_rate'],\n",
    "    noise_rate=config['noise_rate'],\n",
    "    ran_flip_conf=None,\n",
    "    )\n",
    "\n",
    "autoencoder.compile(\n",
    "    metrics=config['ae_metrics'],\n",
    "    optimizer=config['ae_optimizer'],\n",
    "    loss=config['ae_loss']\n",
    ")\n",
    "# initializing clustering model\n",
    "clustering_model = create_clustering_model(\n",
    "    n_clusters=N_CLUSTERS,\n",
    "    encoder=encoder,\n",
    "    alpha=N_CLUSTERS-1\n",
    ")\n",
    "# compiling the clustering model (necessary for evaluating)\n",
    "clustering_model.compile(loss='kld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.set_weights(encoder_ft_param)\n",
    "z = encoder(x_train).numpy()\n",
    "encoder.set_weights(encoder_final_param)\n",
    "clustering_model.get_layer(\n",
    "    name='clustering').set_weights([final_centroids])\n",
    "y_pred = clustering_model(x_train).numpy().argmax(1)\n",
    "'''\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    random_state=51550,\n",
    "    n_jobs=-1,\n",
    "    #verbose=10\n",
    "    ).fit_transform(z)\n",
    "\n",
    "print('tsne done')\n",
    "dbcl_tsne = DBSCAN(\n",
    "    min_samples=40,\n",
    "    eps=3,\n",
    "    n_jobs=-1,\n",
    "    #verbose=10\n",
    "    ).fit(tsne)\n",
    "print('dbscan1 done')\n",
    "dbcl = DBSCAN(\n",
    "    #min_samples=5,\n",
    "    eps=35,\n",
    "    n_jobs=-1,\n",
    "    #verbose=10\n",
    "    ).fit(z)\n",
    "print('dbscan2 done')'''\n",
    "N_CLUSTERS = 10\n",
    "kmeans = KMeans(\n",
    "    n_clusters=N_CLUSTERS,\n",
    "    #verbose=10\n",
    "    ).fit(z)\n",
    "print('kmeans done')\n",
    "print('Accuracies obtained')\n",
    "#labels_list = [dbcl_tsne.labels_, y_pred, dbcl.labels_, kmeans.labels_, y_train]\n",
    "#descs_list = ['dbscan_tsne', 'dec', 'dbscan', 'kmeans', 'ground_truth']\n",
    "labels_list = [y_pred, kmeans.labels_, y_train]\n",
    "descs_list = ['dec', 'kmeans', 'ground_truth']\n",
    "for labels, desc in zip(labels_list[:-1], descs_list[:-1]):\n",
    "    n_classes = len(np.unique(labels))\n",
    "    if n_classes > 1:\n",
    "        accuracy = my_metrics.acc(y_train, labels)\n",
    "        s_accuracy = (n_classes/(n_classes-1))*accuracy-(1/(n_classes-1))\n",
    "        nmi_score = my_metrics.nmi(y_train, labels)\n",
    "        print('\\t{}: acc {}, s_acc {}, nmi {}, {} labels'. \\\n",
    "            format(desc, accuracy, s_accuracy, nmi_score, n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some final stats\n",
    "encoder.set_weights(encoder_final_param)\n",
    "clustering_model.get_layer(\n",
    "    name='clustering').set_weights([final_centroids])\n",
    "\n",
    "feat_test = encoder(x_test)\n",
    "# computations to see the effective retro-projecting capability of DEC\n",
    "loss = autoencoder.evaluate(x_test, x_test, verbose=0)\n",
    "x_ae_test = autoencoder(x_test)\n",
    "y_pred = clustering_model.predict(x_test, verbose=0).argmax(1)\n",
    "y_ae_pred = clustering_model.predict(np.round(x_ae_test), verbose=0).argmax(1)\n",
    "print('Final cycle accuracy is {}\\nFinal accuracy is {}\\n{} loss is {}'. \\\n",
    "    format(my_metrics.acc(y_pred, y_ae_pred), my_metrics.acc(y_pred, y_test), LOSS, loss))\n",
    "\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(y_pred, y_ae_pred)\n",
    "plt.figure(figsize=(16, 14), facecolor='white',)\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', annot_kws={'size': 20})\n",
    "plt.title('Confusion matrix', fontsize=30)\n",
    "plt.ylabel('Predicted Label', fontsize=25)\n",
    "plt.xlabel('Cycle Predicted Label', fontsize=25)\n",
    "plt.savefig(results_path/'conf_matrix_cycle_accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(y_pred, y_test)\n",
    "plt.figure(figsize=(16, 14), facecolor='white',)\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', annot_kws={'size': 20})\n",
    "plt.title('Confusion matrix', fontsize=30)\n",
    "plt.ylabel('Predicted Label', fontsize=25)\n",
    "plt.xlabel('True Label', fontsize=25)\n",
    "plt.savefig(results_path/'conf_matrix_accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "feat_centroids = np.array(clustering_model.get_layer(name='clustering').get_weights())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradients plot\n",
    "for alpha in [1, 9]:\n",
    "    # set weights\n",
    "    encoder.set_weights(encoder_ft_param)\n",
    "    # initializing clustering model\n",
    "    clustering_model = create_clustering_model(\n",
    "        n_clusters=N_CLUSTERS,\n",
    "        alpha=alpha,\n",
    "        encoder=encoder)\n",
    "    # compiling the clustering model (necessary for evaluating)\n",
    "    clustering_model.compile(\n",
    "        loss='kld')\n",
    "    clustering_model.get_layer(\n",
    "        name='clustering').set_weights([initial_centroids])\n",
    "    cl_layer = clustering_model.get_layer(name='clustering')\n",
    "    # get soft assignments\n",
    "    q = clustering_model(x_train).numpy()\n",
    "    p = target_distribution(q)\n",
    "    initial_pred = q.argmax(1)\n",
    "\n",
    "    # compute gradients\n",
    "    z = encoder(x_train).numpy()\n",
    "    qq = (q.T/q.sum(axis=1)).T\n",
    "    pp = (qq**2)\n",
    "    pp = (pp.T/pp.sum(axis=1)).T\n",
    "    grad = ((alpha+1.0)/alpha)/(1.0+cdist(z, initial_centroids, 'sqeuclidean')/alpha)*(pp-qq)*cdist(z, initial_centroids, 'cityblock')\n",
    "\n",
    "    fig, axs = plt.subplots(2, int(N_CLUSTERS/2),\n",
    "                            figsize=(30, 10),\n",
    "                            squeeze=True,\n",
    "                            facecolor='white',\n",
    "                            dpi=200)\n",
    "    k=0\n",
    "    ind = np.bincount(q.argmax(axis=1)).argmin()\n",
    "    colors = cm.rainbow(np.linspace(0, 1, N_CLUSTERS))\n",
    "    for i in range(2):\n",
    "        for j in range(int(N_CLUSTERS/2)):\n",
    "            idx = (initial_pred == k)\n",
    "            ax = axs[i, j]\n",
    "            scatter = ax.scatter(qq[idx, ind],\n",
    "                                 grad[idx, ind],\n",
    "                                 color=colors[k],\n",
    "                                 s=[20]*len(p[idx, k]),\n",
    "                                 )\n",
    "            ax.set_xlabel(r'$p_{i%d}$' % k)\n",
    "            ax.set_ylabel(r'$|\\frac{\\partial L}{\\partial z_i}|$')\n",
    "            ax.grid()\n",
    "            k+=1\n",
    "    plt.savefig(results_path/'initial_gradients_dec_alpha{}.png'.format(alpha),\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none')\n",
    "\n",
    "\n",
    "    datapoints = tf.Variable(x_train, dtype=tf.float32)\n",
    "    soft_assignments = tf.Variable(p)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        embedded_points = encoder(datapoints)\n",
    "        outputs = cl_layer(embedded_points)\n",
    "        kld = kl_divergence(soft_assignments, outputs)\n",
    "        dc_da = tape.gradient(kld, embedded_points)\n",
    "\n",
    "    norm_dc_da = np.linalg.norm(dc_da, axis=1)\n",
    "\n",
    "    fig, axs = plt.subplots(2, int(N_CLUSTERS/2),\n",
    "                            figsize=(30, 10),\n",
    "                            squeeze=True,\n",
    "                            facecolor='white',\n",
    "                            dpi=200)\n",
    "    k=0\n",
    "    colors = cm.rainbow(np.linspace(0, 1, N_CLUSTERS))\n",
    "    for i in range(2):\n",
    "        for j in range(int(N_CLUSTERS/2)):\n",
    "            idx = (initial_pred == k)\n",
    "            ax = axs[i, j]\n",
    "            scatter = ax.scatter(p[idx, k],\n",
    "                                 norm_dc_da[idx],\n",
    "                                 color=colors[k],\n",
    "                                 s=[20]*len(p[idx, k]),\n",
    "                                 )\n",
    "            ax.set_xlabel(r'$p_{i%d}$' % k)\n",
    "            ax.set_ylabel(r'$|\\frac{\\partial L}{\\partial z_i}|$')\n",
    "            ax.grid()\n",
    "            k+=1\n",
    "    plt.savefig(results_path/'initial_gradients_alpha{}.png'.format(alpha),\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.set_weights(encoder_final_param)\n",
    "z = encoder(x_train).numpy()\n",
    "delta = 1.0\n",
    "\n",
    "for labels, desc in zip(labels_list, descs_list):\n",
    "    print('Visualizing {} labels'.format(desc))\n",
    "    centroids = None\n",
    "    if labels is not None:\n",
    "        centroids = []\n",
    "        n_clusters_found = len(np.unique(labels))\n",
    "        for i in np.unique(labels):\n",
    "            idx = (labels == i)\n",
    "            centroids.append(compute_centroid_np(z[idx, :]))\n",
    "        a = np.concatenate((z, centroids), axis=0)\n",
    "    \n",
    "    tsne = TSNE(n_components=2,\n",
    "                n_jobs=-1,\n",
    "                random_state=51550).fit_transform(a)\n",
    "    \n",
    "    points = pd.DataFrame(tsne[:len(x_train)], columns=['x0', 'x1'])\n",
    "    centroids = pd.DataFrame(tsne[len(x_train):], columns=['x0', 'x1'])\n",
    "    centroids['y'] = ['label {}'.format(l) for l in np.unique(labels)]\n",
    "    centroids['y'] = centroids['y'].astype(\"category\")\n",
    "    points['y'] = ['label {}'.format(l) for l in labels]\n",
    "    points['y'] = points['y'].astype(\"category\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    x_range = (np.min(points['x0'])-delta, np.max(points['x0'])+delta)\n",
    "    y_range = (np.min(points['x1'])-delta, np.max(points['x1'])+delta)\n",
    "    \n",
    "    agg = ds.count()\n",
    "    cmap = None\n",
    "    if centroids is not None:\n",
    "        cmap = 'tab10'\n",
    "        dsshow(df=centroids, glyph=ds.Point('x0','x1'), aggregator=ds.count_cat('y'), ax=ax,\n",
    "            shade_hook=partial(dtf.spread, px=5, shape='square'), cmap=cmap, x_range=x_range, y_range=y_range)\n",
    "        agg = ds.count_cat('y')\n",
    "        \n",
    "    artist = dsshow(df=points, glyph=ds.Point('x0','x1'), aggregator=agg, ax=ax,\n",
    "            shade_hook=partial(dtf.spread, px=2), cmap=cmap, x_range=x_range, y_range=y_range)\n",
    "    #ax.legend(handles=artist.get_legend_elements())\n",
    "    plt.grid()\n",
    "    plt.xlabel(r'$\\tilde{x}_0$')\n",
    "    plt.ylabel(r'$\\tilde{x}_1$')\n",
    "    plt.savefig(results_path/'cluster_tsne_space_{}.png'.format(desc))\n",
    "    plt.show()\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.set_weights(encoder_ft_param)\n",
    "z = encoder(x_train).numpy()\n",
    "delta = 1.0\n",
    "\n",
    "for labels, desc in zip(labels_list, descs_list):\n",
    "    print('Visualizing {} labels'.format(desc))\n",
    "    centroids = None\n",
    "    if labels is not None:\n",
    "        centroids = []\n",
    "        n_clusters_found = len(np.unique(labels))\n",
    "        for i in np.unique(labels):\n",
    "            idx = (labels == i)\n",
    "            centroids.append(compute_centroid_np(z[idx, :]))\n",
    "        a = np.concatenate((z, centroids), axis=0)\n",
    "    \n",
    "    tsne = TSNE(n_components=2,\n",
    "                n_jobs=-1,\n",
    "                random_state=51550).fit_transform(a)\n",
    "    \n",
    "    points = pd.DataFrame(tsne[:len(x_train)], columns=['x0', 'x1'])\n",
    "    centroids = pd.DataFrame(tsne[len(x_train):], columns=['x0', 'x1'])\n",
    "    centroids['y'] = ['label {}'.format(l) for l in np.unique(labels)]\n",
    "    centroids['y'] = centroids['y'].astype(\"category\")\n",
    "    points['y'] = ['label {}'.format(l) for l in labels]\n",
    "    points['y'] = points['y'].astype(\"category\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    x_range = (np.min(points['x0'])-delta, np.max(points['x0'])+delta)\n",
    "    y_range = (np.min(points['x1'])-delta, np.max(points['x1'])+delta)\n",
    "    \n",
    "    agg = ds.count()\n",
    "    cmap = None\n",
    "    if centroids is not None:\n",
    "        cmap = 'tab10'\n",
    "        dsshow(df=centroids, glyph=ds.Point('x0','x1'), aggregator=ds.count_cat('y'), ax=ax,\n",
    "            shade_hook=partial(dtf.spread, px=5, shape='square'), cmap=cmap, x_range=x_range, y_range=y_range)\n",
    "        agg = ds.count_cat('y')\n",
    "        \n",
    "    artist = dsshow(df=points, glyph=ds.Point('x0','x1'), aggregator=agg, ax=ax,\n",
    "            shade_hook=partial(dtf.spread, px=2), cmap=cmap, x_range=x_range, y_range=y_range)\n",
    "    #ax.legend(handles=artist.get_legend_elements())\n",
    "    plt.grid()\n",
    "    plt.xlabel(r'$\\tilde{x}_0$')\n",
    "    plt.ylabel(r'$\\tilde{x}_1$')\n",
    "    plt.savefig(results_path/'finetune_tsne_space_{}.png'.format(desc))\n",
    "    plt.show()\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.set_weights(encoder_param)\n",
    "z = encoder(x_test).numpy()\n",
    "delta = 1.0\n",
    "tsne = TSNE(n_components=2, random_state=51550).fit_transform(z)\n",
    "points = pd.DataFrame(tsne, columns=['x0', 'x1'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "x_range = (np.min(points['x0'])-delta, np.max(points['x0'])+delta)\n",
    "y_range = (np.min(points['x1'])-delta, np.max(points['x1'])+delta)\n",
    "artist = dsshow(points, ds.Point('x0','x1'), ds.count(), ax=ax,\n",
    "      shade_hook=partial(dtf.spread, px=2), x_range=x_range, y_range=y_range)\n",
    "ax.grid()\n",
    "ax.set_xlabel(r'$\\tilde{x}_0$')\n",
    "ax.set_ylabel(r'$\\tilde{x}_1$')\n",
    "plt.savefig(results_path/'pretrain_tsne_space.png')\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.set_weights(encoder_final_param)\n",
    "z = encoder(x_train).numpy()\n",
    "delta = 0.1\n",
    "    \n",
    "points = pd.DataFrame(z, columns=['z{}'.format(i) for i in range(dims[-1])])\n",
    "\n",
    "for labels, desc in zip(labels_list, descs_list):\n",
    "    print('Visualizing {} labels'.format(desc))\n",
    "    centroids = None\n",
    "    if labels is not None:\n",
    "        centroids = []\n",
    "        n_clusters_found = len(np.unique(labels))\n",
    "        for i in np.unique(labels):\n",
    "            idx = (labels == i)\n",
    "            centroids.append(compute_centroid_np(z[idx, :]))\n",
    "    \n",
    "    centroids = pd.DataFrame(centroids, columns=['z{}'.format(i) for i in range(dims[-1])])\n",
    "    centroids['y'] = ['label {}'.format(l) for l in np.unique(labels)]\n",
    "    centroids['y'] = centroids['y'].astype(\"category\")\n",
    "    points['y'] = ['label {}'.format(l) for l in labels]\n",
    "    points['y'] = points['y'].astype(\"category\")\n",
    "    \n",
    "    fig, axs = plt.subplots(dims[-1], dims[-1],\n",
    "                            figsize=(8*dims[-1], 4*dims[-1]),\n",
    "                            squeeze=False,\n",
    "                            facecolor='white',\n",
    "                            dpi=200)\n",
    "    for i in range(dims[-1]):\n",
    "        for j in range(dims[-1]):\n",
    "            ax = axs[i, j]\n",
    "            x_range = (np.min(points['z{}'.format(i)])-delta, np.max(points['z{}'.format(i)])+delta)\n",
    "            y_range = (np.min(points['z{}'.format(j)])-delta, np.max(points['z{}'.format(j)])+delta)\n",
    "            if i!=j:\n",
    "                agg = ds.count()\n",
    "                cmap = None\n",
    "                if centroids is not None:\n",
    "                    cmap = 'tab10'\n",
    "                    dsshow(df=centroids, glyph=ds.Point('z{}'.format(i),'z{}'.format(j)), aggregator=ds.count_cat('y'), ax=axs[i, j],\n",
    "                      shade_hook=partial(dtf.spread, px=5, shape='square'), cmap=cmap, x_range=x_range, y_range=y_range)\n",
    "                    agg = ds.count_cat('y')\n",
    "                    \n",
    "                artist = dsshow(df=points, glyph=ds.Point('z{}'.format(i),'z{}'.format(j)), aggregator=agg, ax=axs[i, j],\n",
    "                      shade_hook=partial(dtf.spread, px=2), cmap=cmap, x_range=x_range, y_range=y_range)\n",
    "                #ax.legend(handles=artist.get_legend_elements())\n",
    "            ax.grid()\n",
    "            ax.set_xlabel(r'$z_{%d}$' % i)\n",
    "            ax.set_ylabel(r'$z_{%d}$' % j)\n",
    "    plt.savefig(results_path/'cluster_feature_space_{}.png'.format(desc),\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.set_weights(encoder_ft_param)\n",
    "z = encoder(x_train).numpy()\n",
    "delta = 0.1\n",
    "    \n",
    "points = pd.DataFrame(z, columns=['z{}'.format(i) for i in range(dims[-1])])\n",
    "\n",
    "for labels, desc in zip(labels_list, descs_list):\n",
    "    print('Visualizing {} labels'.format(desc))\n",
    "    centroids = None\n",
    "    if labels is not None:\n",
    "        centroids = []\n",
    "        n_clusters_found = len(np.unique(labels))\n",
    "        for i in np.unique(labels):\n",
    "            idx = (labels == i)\n",
    "            centroids.append(compute_centroid_np(z[idx, :]))\n",
    "    \n",
    "    centroids = pd.DataFrame(centroids, columns=['z{}'.format(i) for i in range(dims[-1])])\n",
    "    centroids['y'] = ['label {}'.format(l) for l in np.unique(labels)]\n",
    "    centroids['y'] = centroids['y'].astype(\"category\")\n",
    "    points['y'] = ['label {}'.format(l) for l in labels]\n",
    "    points['y'] = points['y'].astype(\"category\")\n",
    "    \n",
    "    fig, axs = plt.subplots(dims[-1], dims[-1],\n",
    "                            figsize=(8*dims[-1], 4*dims[-1]),\n",
    "                            squeeze=False,\n",
    "                            facecolor='white',\n",
    "                            dpi=200)\n",
    "    for i in range(dims[-1]):\n",
    "        for j in range(dims[-1]):\n",
    "            ax = axs[i, j]\n",
    "            x_range = (np.min(points['z{}'.format(i)])-delta, np.max(points['z{}'.format(i)])+delta)\n",
    "            y_range = (np.min(points['z{}'.format(j)])-delta, np.max(points['z{}'.format(j)])+delta)\n",
    "            if i!=j:\n",
    "                agg = ds.count()\n",
    "                cmap = None\n",
    "                if centroids is not None:\n",
    "                    cmap = 'tab10'\n",
    "                    dsshow(df=centroids, glyph=ds.Point('z{}'.format(i),'z{}'.format(j)), aggregator=ds.count_cat('y'), ax=axs[i, j],\n",
    "                      shade_hook=partial(dtf.spread, px=5, shape='square'), cmap=cmap, x_range=x_range, y_range=y_range)\n",
    "                    agg = ds.count_cat('y')\n",
    "                    \n",
    "                artist = dsshow(df=points, glyph=ds.Point('z{}'.format(i),'z{}'.format(j)), aggregator=agg, ax=axs[i, j],\n",
    "                      shade_hook=partial(dtf.spread, px=2), cmap=cmap, x_range=x_range, y_range=y_range)\n",
    "                #ax.legend(handles=artist.get_legend_elements())\n",
    "            ax.grid()\n",
    "            ax.set_xlabel(r'$z_{%d}$' % i)\n",
    "            ax.set_ylabel(r'$z_{%d}$' % j)\n",
    "    plt.savefig(results_path/'finetune_feature_space_{}.png'.format(desc),\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.set_weights(encoder_param)\n",
    "z = encoder(x_test).numpy()\n",
    "delta = 0.1\n",
    "    \n",
    "points = pd.DataFrame(z, columns=['z{}'.format(i) for i in range(dims[-1])])\n",
    "\n",
    "fig, axs = plt.subplots(dims[-1], dims[-1],\n",
    "                        figsize=(8*dims[-1], 4*dims[-1]),\n",
    "                        squeeze=False,\n",
    "                        facecolor='white',\n",
    "                        dpi=200)\n",
    "for i in range(dims[-1]):\n",
    "    for j in range(dims[-1]):\n",
    "        ax = axs[i, j]\n",
    "        x_range = (np.min(points['z{}'.format(i)])-delta, np.max(points['z{}'.format(i)])+delta)\n",
    "        y_range = (np.min(points['z{}'.format(j)])-delta, np.max(points['z{}'.format(j)])+delta)\n",
    "        if i!=j:\n",
    "            artist = dsshow(points, ds.Point('z{}'.format(i),'z{}'.format(j)), ds.count(), ax=axs[i, j],\n",
    "                  shade_hook=partial(dtf.spread, px=2), x_range=x_range, y_range=y_range)\n",
    "        ax.grid()\n",
    "        ax.set_xlabel(r'$z_{%d}$' % i)\n",
    "        ax.set_ylabel(r'$z_{%d}$' % j)\n",
    "plt.savefig(results_path/'pretrain_feature_space_{}.png'.format(desc),\n",
    "            facecolor=fig.get_facecolor(),\n",
    "            edgecolor='none')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example BMNIST digits\n",
    "figure = plt.figure(figsize=(20, 4), facecolor='white',)\n",
    "j = 0\n",
    "\n",
    "for example in x_train[:10]:\n",
    "  plt.subplot(2, 5, j+1)\n",
    "  plt.imshow(example.reshape((28,28)), cmap='gray', aspect='equal')\n",
    "  plt.axis('off')\n",
    "  j += 1\n",
    "plt.savefig(results_path/'img_orig.png',\n",
    "            facecolor=fig.get_facecolor(),\n",
    "            edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example BMNIST digits from pretrained autoencoder\n",
    "encoder.set_weights(encoder_param)\n",
    "figure = plt.figure(figsize=(20, 4), facecolor='white',)\n",
    "j = 0\n",
    "\n",
    "for example in autoencoder(x_train[:10]):\n",
    "  plt.subplot(2, 5, j+1)\n",
    "  plt.imshow(example.numpy().reshape((28,28)), cmap='gray', aspect='equal')\n",
    "  plt.axis('off')\n",
    "  j += 1\n",
    "plt.savefig(results_path/'img_r_pretrain.png',\n",
    "            facecolor=fig.get_facecolor(),\n",
    "            edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example BMNIST digits from finetuned autoencoder\n",
    "encoder.set_weights(encoder_ft_param)\n",
    "figure = plt.figure(figsize=(20, 4), facecolor='white',)\n",
    "j = 0\n",
    "\n",
    "for example in autoencoder(x_train[:10]):\n",
    "  plt.subplot(2, 5, j+1)\n",
    "  plt.imshow(example.numpy().reshape((28,28)), cmap='gray', aspect='equal')\n",
    "  plt.axis('off')\n",
    "  j += 1\n",
    "plt.savefig(results_path/'img_r_finetune.png',\n",
    "            facecolor=fig.get_facecolor(),\n",
    "            edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example BMNIST digits from final model\n",
    "encoder.set_weights(encoder_final_param)\n",
    "figure = plt.figure(figsize=(20, 4), facecolor='white',)\n",
    "j = 0\n",
    "\n",
    "for example in autoencoder(x_train[:10]):\n",
    "  plt.subplot(2, 5, j+1)\n",
    "  plt.imshow(example.numpy().reshape((28,28)), cmap='gray', aspect='equal')\n",
    "  plt.axis('off')\n",
    "  j += 1\n",
    "plt.savefig(results_path/'img_r_final.png',\n",
    "            facecolor=fig.get_facecolor(),\n",
    "            edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24f6449c2766f597e442bf0c6b08f70e85c443f010de0cdb87db978cb9e1ec44"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
