{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import sys\n","import pathlib\n","import numpy as np\n","import pandas as pd\n","from numpy.random import multivariate_normal\n","from scipy.stats import mode\n","from scipy.spatial.distance import cdist\n","import sklearn\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n","from MulticoreTSNE import MulticoreTSNE as TSNE\n","# from sklearn.manifold import TSNE\n","from sklearn.cluster import DBSCAN, KMeans\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","from lifelines import (KaplanMeierFitter, WeibullFitter, ExponentialFitter,\n","                       LogNormalFitter, LogLogisticFitter, PiecewiseExponentialFitter,\n","                       GeneralizedGammaFitter, SplineFitter)\n","\n","# Make TensorFlow log less verbose\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n","\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.initializers import VarianceScaling\n","from tensorflow.keras.losses import kl_divergence\n","\n","import umap\n","import hdbscan\n","from mdutils.mdutils import MdUtils\n","\n","from flwr.common.typing import Parameters\n","\n","FLP_path = pathlib.Path('/home/relogu/Desktop/OneDrive/UNIBO/Magistrale/Federated Learning Project').absolute()\n","sys.path.insert(1, str(FLP_path))\n","from py.losses import get_keras_loss\n","from py.dataset_util import get_euromds_dataset, get_euromds_ids, get_outcome_euromds_dataset, fillcolumn_prob\n","from py.dec.util import create_autoencoder, create_clustering_model, target_distribution\n","from py.util import compute_centroid_np, get_dims_from_weights, return_not_binary_indices\n","import py.metrics as my_metrics\n","\n","results_path = pathlib.Path('/home/relogu/Desktop/OneDrive/UNIBO/Magistrale/Federated Learning Project/output_dec_euromds')\n","N_CLUSTERS = 20\n","LOSS = 'mse'\n","\n","# disable possible gpu devices for this kernel\n","tf.config.set_visible_devices([], 'GPU')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# prefix = 'aggregated_weights_'\n","encoder_param = np.load(results_path/str('encoder.npz'),\n","                        allow_pickle=True)\n","encoder_param = np.squeeze(np.array([encoder_param[p] for p in encoder_param]))\n","encoder_ft_param = np.load(results_path/str('encoder_ft.npz'),\n","                           allow_pickle=True)\n","encoder_ft_param = np.squeeze(np.array([encoder_ft_param[p] for p in encoder_ft_param]))\n","encoder_final_param = np.load(results_path/str('encoder_final.npz'),\n","                              allow_pickle=True)\n","encoder_final_param = np.squeeze(np.array([encoder_final_param[p] for p in encoder_final_param]))\n","initial_centroids = np.load(results_path/'initial_centroids.npz',\n","                            allow_pickle=True)\n","initial_centroids = np.array([initial_centroids[p] for p in initial_centroids])\n","final_centroids = np.load(results_path/str('final_centroids.npz'),\n","                          allow_pickle=True)\n","final_centroids = np.array([final_centroids[p] for p in final_centroids])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Initial Centroids: {}'.format(initial_centroids))\n","print('Final Centroids: {}'.format(final_centroids))\n","delta_centroids = final_centroids-initial_centroids\n","print('Delta Centroids: {}'.format(delta_centroids))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["FILL = True\n","groups = ['CNA', 'Genetics']\n","ex_cols = ['UTX', 'CSF3R', 'SETBP1', 'PPM1D']\n","if FILL:\n","    accept_nan = 2044\n","    img_shape = (6,9)\n","else:\n","    accept_nan = 0\n","    img_shape = (5,8)\n","x = get_euromds_dataset(\n","    groups=groups,\n","    exclude_cols=ex_cols,\n","    accept_nan=accept_nan,\n","    fill_fn=fillcolumn_prob)\n","columns = x.columns\n","# getting labels from HDP\n","prob = get_euromds_dataset(groups=['HDP'])\n","y = []\n","for label, row in prob.iterrows():\n","    if np.sum(row) > 0:\n","        y.append(row.argmax())\n","    else:\n","        y.append(-1)\n","y = np.array(y)\n","# getting the outcomes\n","outcomes = get_outcome_euromds_dataset()\n","# getting IDs\n","ids = get_euromds_ids()\n","n_features = len(x.columns)\n","x = np.array(x)\n","outcomes = np.array(outcomes[['outcome_3', 'outcome_2']])\n","ids = np.array(ids)\n","y_pred = pd.read_csv(results_path/'pred.csv')\n","y_pred = np.array(y_pred.sort_values(by=['Unnamed: 0'])['label'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["up_frequencies = np.array([np.array(np.count_nonzero(\n","    x[:, i])/x.shape[0]) for i in range(n_features)])\n","nb_idx = return_not_binary_indices(x)\n","b_idx = list(range(len(x[0,:])))[len(nb_idx):]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# setting up the autoencoder\n","dims = get_dims_from_weights(encoder_param)\n","config = {\n","    'binary': False,\n","    'tied': True,\n","    'dims': dims,\n","    'dropout': 0.0,\n","    'ran_flip': 0.0,\n","    'act': 'selu',\n","    'ortho': False,\n","    'u_norm': True,\n","    'init': None,\n","    'b_idx': b_idx,\n","    'use_bias': True,\n","    'ae_metrics': [\n","        # my_metrics.get_rounded_accuracy(idx=b_idx),\n","        # my_metrics.get_slice_accuracy(idx=nb_idx),\n","        # my_metrics.get_slice_hamming_loss(mode='multilabel', threshold=0.50, idx=b_idx),\n","        # my_metrics.get_slice_log_mse_loss(idx=nb_idx)\n","        ],\n","}\n","autoencoder, encoder, decoder = create_autoencoder(\n","    config, None\n",")\n","# compiling the autoencoder (necessary for evaluating)\n","autoencoder.compile(\n","    loss=get_keras_loss(LOSS),\n","    metrics=config['ae_metrics'],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kmeans.cluster_centers_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# compiling the clustering model (necessary for evaluating)\n","encoder.set_weights(encoder_ft_param)\n","z = encoder(x).numpy()\n","kmeans = KMeans(\n","    n_clusters=N_CLUSTERS,\n","    n_init=20\n","    ).fit(z)\n","centroids = []\n","n_classes = len(np.unique(kmeans.labels_))\n","for i in np.unique(kmeans.labels_):\n","    idx = (kmeans.labels_ == i)\n","    centroids.append(compute_centroid_np(z[idx,:]))\n","# saving the model weights\n","centroids = np.array([centroids])\n","clustering_model = create_clustering_model(\n","    n_clusters=8,\n","    alpha=1,\n","    encoder=encoder)\n","clustering_model.get_layer(\n","    name='clustering').set_weights(centroids)\n","clustering_model.compile(\n","    optimizer=tf.keras.optimizers.SGD(\n","        learning_rate=0.001,\n","        momentum=0.9\n","        ),\n","    loss='kld')\n","clustering_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_q = clustering_model(x).numpy()\n","# update the auxiliary target distribution p\n","train_p = target_distribution(train_q)\n","clustering_model.fit(x=x,\n","                     y=train_p,\n","                     verbose=2,\n","                     batch_size=100)\n","q = clustering_model(x).numpy().argmax(1)\n","tol = float(1 - np.sum(kmeans.labels_==q)/len(x))\n","print(tol)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_centroids = clustering_model.get_layer(\n","    name='clustering').get_weights()\n","diff = new_centroids - np.array([kmeans.cluster_centers_])\n","print(np.sum(diff))\n","print(diff)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_centroids = clustering_model.get_layer(\n","    name='clustering').get_weights()\n","diff = new_centroids - np.array([kmeans.cluster_centers_])\n","np.sum(diff)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoder.set_weights(encoder_ft_param)\n","z = encoder(x).numpy()\n","tsne = TSNE(\n","    n_components=2,\n","    n_jobs=-1,\n","    random_state=51550).fit_transform(z)\n","dbcl_tsne = DBSCAN(\n","    min_samples=40,\n","    eps=3,\n","    ).fit(tsne)\n","dbcl = DBSCAN(\n","    #min_samples=5,\n","    eps=35,\n","    ).fit(z)\n","N_CLUSTERS = 8\n","kmeans = KMeans(\n","    n_clusters=N_CLUSTERS\n","    ).fit(z)\n","print('Accuracies obtained (HDP as ground-truth, 6+1 labels)')\n","labels_list = [dbcl_tsne.labels_, y_pred, dbcl.labels_, kmeans.labels_, y, None]\n","descs_list = ['dbscan_tsne', 'dec', 'dbscan', 'kmeans', 'hdp', 'nolabels']\n","# for labels, desc in zip(labels_list[:-1], descs_list[:-1]):\n","#     n_classes = len(np.unique(labels))\n","#     accuracy =  my_metrics.acc(y, labels)\n","#     s_accuracy = (n_classes/(n_classes-1))*accuracy-(1/(n_classes-1))\n","#     nmi_score = my_metrics.nmi(y, labels)\n","#     print('\\t{}: acc {}, s_acc {}, nmi {}, {} labels'. \\\n","#         format(desc, accuracy, s_accuracy, nmi_score, n_classes))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ## some stats\n","# # initializing clustering model\n","# clustering_model = create_clustering_model(\n","#     n_clusters=13,\n","#     alpha=1,\n","#     encoder=encoder)\n","# # compiling the clustering model (necessary for evaluating)\n","# clustering_model.compile(\n","#     loss='kld')\n","# encoder.set_weights(encoder_final_param)\n","# clustering_model.get_layer(\n","#     name='clustering').set_weights(final_centroids[0])\n","# feat_test = encoder(x)\n","# # computations to see the effective retro-projecting capability of DEC\n","# loss = autoencoder.evaluate(x, x, verbose=0)\n","# x_ae_test = autoencoder(x)\n","# y_pred = clustering_model.predict(x, verbose=0).argmax(1)\n","# y_ae_pred = clustering_model.predict(np.round(x_ae_test), verbose=0).argmax(1)\n","# print('Cycle accuracy is {}\\n{} loss is {}'.\n","#       format(my_metrics.acc(y_pred, y_ae_pred), LOSS, loss))\n","# confusion_matrix = sklearn.metrics.confusion_matrix(y_pred, y_ae_pred)\n","# plt.figure(figsize=(16, 14))\n","# sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", annot_kws={\"size\": 20})\n","# plt.title(\"Confusion matrix\", fontsize=30)\n","# plt.ylabel('Predicted Label', fontsize=25)\n","# plt.xlabel('Cycle Predicted Label', fontsize=25)\n","# plt.savefig(results_path/'conf_matrix_cycle_accuracy.png')\n","# plt.close()\n","\n","# print(\"{},{},{},{},{}\\n{},{},{},{},{}\\n{},{},{},{},{}\\n{},{},{},{},{}\\n\"\n","#         \"{},{},{},{},{}\\n{},{},{},{},{}\\n{},{},{},{},{}\\n{},{},{},{},{}\".format(*columns))\n","\n","# for labels, desc in zip(labels_list[:-1], descs_list[:-1]):\n","#     print(\"Get properties of {} labels\".format(desc))\n","#     centroids = None\n","#     if labels is not None:\n","#         centroids = []\n","#         n_clusters_found = len(np.unique(labels))\n","#         for i in np.unique(labels):\n","#             idx = (labels == i)\n","#             centroids.append(compute_centroid_np(z[idx, :]))\n","#     #centroids\n","#     x_ae_centroids = decoder.predict(np.array(centroids))\n","#     r_x_ae_centroids = np.round(x_ae_centroids)\n","#     drivers = pd.DataFrame(data=r_x_ae_centroids, columns=columns)\n","#     font = {'family': 'sans-serif',\n","#             'size': 15}\n","#     matplotlib.rc('font', **font)\n","#     #cov = np.array([1*np.std(centroids, axis=0)]*N_CLUSTERS)\n","#     #print('Centroid {}\\nVariations{}'.format(centroids[0], multivariate_normal(centroids[0], cov, size=10)))\n","#     silhests, nearests, s_means, s_modes, means, modes = \\\n","#         pd.DataFrame(), pd.DataFrame(), pd.DataFrame(\n","#         ), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n","#     silh = sklearn.metrics.silhouette_samples(feat_test, labels)\n","#     for i, feat_centroid in enumerate(centroids):\n","#         if len(labels[labels == i]) > 0:\n","#             distances = [np.linalg.norm(feat_centroid-f_t)\n","#                          for f_t in feat_test]\n","#             cov = np.array([5*np.std(feat_test[labels == i], axis=0)]*dims[-1])\n","#             feat_samples = multivariate_normal(feat_centroid, cov, size=100)\n","#             x_samples = decoder.predict(feat_samples)\n","#             r_x_samples = np.round(x_samples)\n","#             x_i = x[labels == i]\n","#             nearests = nearests.append(pd.DataFrame(\n","#                 data=[x[np.argmin(distances)]], columns=columns))\n","#             silhests = silhests.append(pd.DataFrame(\n","#                 data=[x_i[np.argmax(silh[labels == i])]], columns=columns))\n","#             means = means.append(pd.DataFrame(\n","#                 data=[np.average(x_i, axis=0)], columns=columns))\n","#             modes = modes.append(pd.DataFrame(\n","#                 data=mode(x_i, axis=0)[0], columns=columns))\n","\n","#             s_means = s_means.append(pd.DataFrame(\n","#                 data=[np.average(x_samples, axis=0)], columns=columns))\n","#             s_modes = s_modes.append(pd.DataFrame(\n","#                 data=mode(r_x_samples, axis=0)[0], columns=columns))\n","\n","#     names = ['Mean', 'Mode', 'Nearest', 'Silh-est',\n","#                 'Centroid', 'S Mean', 'S Mode']\n","#     dfs = [means, modes, nearests, silhests,\n","#             drivers, s_means, s_modes]\n","#     for name, df in zip(names, dfs):\n","#         fig, ax = plt.subplots(\n","#             1, n_clusters_found, figsize=(2*n_clusters_found, 3))\n","#         for j, i in enumerate(np.unique(labels)):\n","#             print('j{},i{}'.format(j, i))\n","#             img = df.to_numpy()[j].reshape(img_shape)\n","#             ax[j].set_title('{} {}'.format(name, i))\n","#             ax[j].imshow(img.squeeze(), interpolation='none', cmap='gray')\n","#             ax[j].axis('off')\n","#             if name in set(names[:2]):\n","#                 ax[j].text(-0.5, 9.0,\n","#                             \"{} samples\".format(len(x[labels == i])))\n","#         plt.savefig(\n","#             results_path/'{}_{}_imgs.png'.format(name.lower().replace(' ', '_'), desc))\n","#         plt.close()\n","#     del drivers, silhests, nearests, s_means, s_modes, means, modes\n","#     del silh, x_ae_test, y_ae_pred, x_ae_centroids, r_x_ae_centroids\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Gradients plot\n","# set weights\n","encoder.set_weights(encoder_ft_param)\n","z = encoder(x).numpy()\n","for labels, desc in zip(labels_list[:-1], descs_list[:-1]):\n","#for labels, desc in zip([kmeans.labels_], 'kmeans'):\n","# for ii in range(3, 15):\n","#     kmeans = KMeans(\n","#         n_clusters=int(ii)\n","#         ).fit(z)\n","#     labels = kmeans.labels_\n","#     desc = 'kmeans{}'.format(ii)\n","    print('Visualizing {} gradients'.format(desc))\n","    centroids = None\n","    lables_list = np.unique(labels[labels>=0])\n","    n_clusters_found = len(lables_list)\n","    if n_clusters_found > 1:\n","        centroids = []\n","        for i in lables_list:\n","            idx = (labels == i)\n","            centroids.append(compute_centroid_np(z[idx,:]))\n","        # initializing clustering model\n","        clustering_model = create_clustering_model(\n","            n_clusters=n_clusters_found,\n","            alpha=1,#max(n_clusters_found-1, 1),\n","            encoder=encoder)\n","        # compiling the clustering model (necessary for evaluating)\n","        clustering_model.compile(\n","            loss='kld')\n","        clustering_model.get_layer(\n","            name='clustering').set_weights(np.array([centroids]))\n","        clustering_model.get_layer(name='clustering').trainable = False\n","        cl_layer = clustering_model.get_layer(name='clustering')\n","        # get soft assignments\n","        q = clustering_model(x).numpy()\n","        soft_labels = q.argmax(1)\n","        p = target_distribution(q)\n","        datapoints = tf.Variable(x, dtype=tf.float32)\n","        soft_assignments = tf.Variable(p)\n","\n","        # # compute gradients dec way\n","        # z = encoder(x).numpy()\n","        # qq = (q.T/q.sum(axis=1)).T\n","        # pp = (qq**2)\n","        # pp = (pp.T/pp.sum(axis=1)).T\n","        # grad = 2.0/(1.0+cdist(z, centroids, 'sqeuclidean'))*(pp-qq)*cdist(z, centroids, 'cityblock')\n","\n","            \n","        # fig, axs = plt.subplots(1, n_clusters_found,\n","        #                         figsize=(10*n_clusters_found, 10),\n","        #                         squeeze=True,\n","        #                         facecolor='white',\n","        #                         dpi=200)\n","        # k=0\n","        # ind = np.bincount(q.argmax(axis=1)).argmin()\n","        # colors = cm.rainbow(np.linspace(0, 1, n_clusters_found))\n","        # colors = cm.rainbow(np.linspace(0, 1, n_clusters_found))\n","        # for i in range(n_clusters_found):\n","        #     idx = (soft_labels == lables_list[k])\n","        #     ax = axs[i]\n","        #     scatter = ax.scatter(qq[idx, ind],\n","        #                         grad[idx, ind],\n","        #                         color=colors[k],\n","        #                         s=[20]*len(p[idx, lables_list[k]]),\n","        #                         )\n","        #     ax.set_xlabel(r'$p_{i%d}$' % lables_list[k])\n","        #     ax.set_ylabel(r'$|\\frac{\\partial L}{\\partial z_i}|$')\n","        #     ax.grid()\n","        #     ax.set_facecolor('gray')\n","        #     k+=1\n","        \n","        # compute gradients tf way\n","        with tf.GradientTape() as tape:\n","            embedded_points = encoder(datapoints)\n","            outputs = cl_layer(embedded_points)\n","            kld = kl_divergence(soft_assignments, outputs)\n","            dc_da = tape.gradient(kld, embedded_points)\n","\n","        norm_dc_da = np.linalg.norm(dc_da, axis=1)\n","            \n","        fig, axs = plt.subplots(1, n_clusters_found,\n","                                figsize=(10*n_clusters_found, 10),\n","                                squeeze=True,\n","                                facecolor='white',\n","                                dpi=200)\n","        k=0\n","        colors = cm.rainbow(np.linspace(0, 1, n_clusters_found))\n","        for i in range(n_clusters_found):\n","            idx = (soft_labels == lables_list[k])\n","            ax = axs[i]\n","            scatter = ax.scatter(p[idx, lables_list[k]],\n","                                norm_dc_da[idx],\n","                                color=colors[k],\n","                                s=[20]*len(p[idx, lables_list[k]]),\n","                                )\n","            ax.set_xlabel(r'$p_{i%d}$' % lables_list[k])\n","            ax.set_ylabel(r'$|\\frac{\\partial L}{\\partial z_i}|$')\n","            ax.grid()\n","            ax.set_facecolor('gray')\n","            k+=1\n","        plt.savefig(results_path/'initial_gradients_{}.png'.format(desc),\n","                    facecolor=fig.get_facecolor(),\n","                    edgecolor='none')\n","        plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["axs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoder.set_weights(encoder_final_param)\n","z = encoder(x).numpy()\n","\n","for labels, desc in zip(labels_list, descs_list):\n","    print('Visualizing {} labels'.format(desc))\n","    a = z\n","    centroids = None\n","    if labels is not None:\n","        centroids = []\n","        n_clusters_found = len(np.unique(labels))\n","        for i in np.unique(labels):\n","            idx = (labels == i)\n","            centroids.append(compute_centroid_np(z[idx,:]))\n","        \n","        a = np.concatenate((z, centroids), axis=0)\n","        \n","    tsne = TSNE(\n","        n_components=2,\n","        n_jobs=-1,\n","        random_state=51550).fit_transform(a)\n","    fig, ax = plt.subplots(figsize=(16, 8))\n","    scatter = plt.scatter(tsne[:len(x), 0],\n","                          tsne[:len(x), 1],\n","                          c=labels,\n","                          s=[25]*len(x),\n","                          cmap='Spectral',\n","                          alpha=0.6)\n","    if labels is not None:\n","        scatter1 = plt.scatter(tsne[len(x):, 0],\n","                               tsne[len(x):, 1],\n","                               c=range(n_clusters_found),\n","                               marker='+',\n","                               s=[1000]*n_clusters_found,\n","                               cmap='Spectral')\n","    plt.grid()\n","    if labels is not None:\n","        ax.set_facecolor('gray')\n","        legend = ax.legend(*scatter.legend_elements(), title=\"Labels\",framealpha=0.3)\n","    plt.xlabel(r'$\\tilde{x}$')\n","    plt.ylabel(r'$\\tilde{y}$')\n","    plt.savefig(results_path/'finetune_tsne_space_{}.png'.format(desc))\n","    plt.show()\n","    #plt.close()\n","del tsne#, a"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoder.set_weights(encoder_ft_param)\n","z = encoder(x).numpy()\n","\n","for labels, desc in zip(labels_list, descs_list):\n","    print('Visualizing {} labels'.format(desc))\n","    a = z\n","    centroids = None\n","    if labels is not None:\n","        centroids = []\n","        n_clusters_found = len(np.unique(labels))\n","        for i in np.unique(labels):\n","            idx = (labels == i)\n","            centroids.append(compute_centroid_np(z[idx,:]))\n","        \n","        a = np.concatenate((z, centroids), axis=0)\n","        \n","    tsne = TSNE(\n","        n_components=2,\n","        n_jobs=-1,\n","        random_state=51550).fit_transform(a)\n","    fig, ax = plt.subplots(figsize=(16, 8))\n","    scatter = plt.scatter(tsne[:len(x), 0],\n","                          tsne[:len(x), 1],\n","                          c=labels,\n","                          s=[25]*len(x),\n","                          cmap='Spectral',\n","                          alpha=0.6)\n","    if labels is not None:\n","        scatter1 = plt.scatter(tsne[len(x):, 0],\n","                               tsne[len(x):, 1],\n","                               c=range(n_clusters_found),\n","                               marker='+',\n","                               s=[1000]*n_clusters_found,\n","                               cmap='Spectral')\n","    plt.grid()\n","    if labels is not None:\n","        ax.set_facecolor('gray')\n","        legend = ax.legend(*scatter.legend_elements(), title=\"Labels\",framealpha=0.3)\n","    plt.xlabel(r'$\\tilde{x}$')\n","    plt.ylabel(r'$\\tilde{y}$')\n","    plt.savefig(results_path/'finetune_tsne_space_{}.png'.format(desc))\n","    plt.show()\n","    #plt.close()\n","del tsne#, a\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoder.set_weights(encoder_param)\n","a = encoder(x).numpy()\n","tsne = TSNE(\n","    n_components=2,\n","    n_jobs=-1,\n","    random_state=51550).fit_transform(a)\n","fig, ax = plt.subplots(figsize=(16, 8))\n","scatter = plt.scatter(tsne[:len(x), 0],\n","                      tsne[:len(x), 1],\n","                      s=[25]*len(x),\n","                      alpha=0.4)\n","plt.grid()\n","#ax.set_facecolor('gray')\n","plt.xlabel(r'$\\tilde{x}$')\n","plt.ylabel(r'$\\tilde{y}$')\n","plt.savefig(results_path/'pretrain_tsne_space.png')\n","#plt.close()\n","del tsne, a"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoder.set_weights(encoder_final_param)\n","z = encoder(x).numpy()\n","\n","for labels, desc in zip(labels_list, descs_list):\n","    print('Visualizing {} labels'.format(desc))\n","    a = z\n","    centroids = None\n","    if labels is not None:\n","        centroids = []\n","        n_clusters_found = len(np.unique(labels))\n","        for i in np.unique(labels):\n","            idx = (labels == i)\n","            centroids.append(compute_centroid_np(z[idx,:]))\n","        \n","        a = np.concatenate((z, centroids), axis=0)\n","    fig, axs = plt.subplots(dims[-1], dims[-1],\n","                            figsize=(8*dims[-1], 4*dims[-1]),\n","                            squeeze=False,\n","                            facecolor='white',\n","                            dpi=200)\n","    for i in range(dims[-1]):\n","        for j in range(dims[-1]):\n","            ax = axs[i, j]\n","            scatter = ax.scatter(a[:len(x), i],\n","                                a[:len(x), j],\n","                                c=labels,\n","                                s=[25]*len(x),\n","                                cmap='Spectral',\n","                                alpha=0.6)\n","            \n","            if centroids is not None:\n","                scatter1 = ax.scatter(a[len(x):, i],\n","                                    a[len(x):, j],\n","                                    c=range(n_clusters_found),\n","                                    marker='+',\n","                                    s=[1000]*n_clusters_found,\n","                                    cmap='Spectral')\n","            ax.grid()\n","            if labels is not None:\n","                ax.set_facecolor('gray')\n","                legend = ax.legend(*scatter.legend_elements(),\n","                                title=\"Labels\",\n","                                framealpha=0.3,\n","                                prop={'size': 6})\n","            ax.set_xlabel(r'$\\tilde{x}_{%d}$' % i)\n","            ax.set_ylabel(r'$\\tilde{x}_{%d}$' % j)\n","            # ax.set_yscale('log')\n","            # ax.set_xscale('log')\n","    plt.savefig(results_path/'cluster_feature_space_{}.png'.format(desc),\n","                facecolor=fig.get_facecolor(),\n","                edgecolor='none')\n","    plt.close()\n","del a"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoder.set_weights(encoder_ft_param)\n","z = encoder(x).numpy()\n","\n","# dbcl1 = DBSCAN(\n","#     #min_samples=5,\n","#     eps=0.1,\n","#     ).fit(z)\n","# zip([dbcl1.labels_], ['dbscan1']):\n","for labels, desc in zip(labels_list, descs_list):\n","    #print('Visualizing {} labels'.format(desc))\n","    a = z\n","    centroids = None\n","    if labels is not None:\n","        centroids = []\n","        n_clusters_found = len(np.unique(labels))\n","        for i in np.unique(labels):\n","            idx = (labels == i)\n","            centroids.append(compute_centroid_np(z[idx,:]))\n","        a = np.concatenate((z, centroids), axis=0)\n","    \n","    fig, axs = plt.subplots(dims[-1], dims[-1],\n","                            figsize=(8*dims[-1], 4*dims[-1]),\n","                            squeeze=False,\n","                            facecolor='white',\n","                            dpi=200)\n","    for i in range(dims[-1]):\n","        for j in range(dims[-1]):\n","            ax = axs[i, j]\n","            scatter = ax.scatter(a[:len(x), i],\n","                                a[:len(x), j],\n","                                c=labels,\n","                                s=[25]*len(x),\n","                                cmap='Spectral',\n","                                alpha=0.6)\n","            \n","            if centroids is not None:\n","                scatter1 = ax.scatter(a[len(x):, i],\n","                                    a[len(x):, j],\n","                                    c=range(n_clusters_found),\n","                                    marker='+',\n","                                    s=[1000]*n_clusters_found,\n","                                    cmap='Spectral')\n","            ax.grid()\n","            if labels is not None:\n","                ax.set_facecolor('gray')\n","                legend = ax.legend(*scatter.legend_elements(),\n","                                title=\"Labels\",\n","                                framealpha=0.3,\n","                                prop={'size': 6})\n","            ax.set_xlabel(r'$\\tilde{x}_{%d}$' % i)\n","            ax.set_ylabel(r'$\\tilde{x}_{%d}$' % j)\n","            # ax.set_yscale('log')\n","            # ax.set_xscale('log')\n","    plt.savefig(results_path/'finetune_feature_space_{}.png'.format(desc),\n","                facecolor=fig.get_facecolor(),\n","                edgecolor='none')\n","    plt.close()\n","del a"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["labels"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoder.set_weights(encoder_param)\n","a = encoder(x).numpy()\n","fig, axs = plt.subplots(dims[-1], dims[-1],\n","                        figsize=(8*dims[-1], 4*dims[-1]),\n","                        squeeze=False,\n","                        facecolor='white',\n","                        dpi=200)\n","for i in range(dims[-1]):\n","    for j in range(dims[-1]):\n","        ax = axs[i, j]\n","        scatter = ax.scatter(a[:len(x), i],\n","                            a[:len(x), j],\n","                            s=[25]*len(x),\n","                            alpha=0.6)\n","        ax.grid()\n","        ax.set_xlabel(r'$\\tilde{x}_{%d}$' % i)\n","        ax.set_ylabel(r'$\\tilde{x}_{%d}$' % j)\n","        # ax.set_yscale('log')\n","        # ax.set_xscale('log')\n","plt.savefig(results_path/'pretrain_feature_space.png',\n","            facecolor=fig.get_facecolor(),\n","            edgecolor='none')\n","plt.close()\n","del a"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fitters = {'KaplanMeierFitter': KaplanMeierFitter(),\n","           'WeibullFitter': WeibullFitter(),\n","            #'ExponentialFitter': ExponentialFitter(),\n","            #'LogNormalFitter': LogNormalFitter(),\n","            #'LogLogisticFitter': LogLogisticFitter(),\n","            #'PiecewiseExponentialFitter': PiecewiseExponentialFitter([40, 60]),\n","            #'GeneralizedGammaFitter': GeneralizedGammaFitter()\n","            #'SplineFitter': SplineFitter(T.loc[E.astype(bool)], [0, 50, 100])\n","            }\n","n_min = 10\n","times = outcomes[:, 0]\n","events = outcomes[:, 1]\n","for labels, desc in zip(labels_list[:-1], descs_list[:-1]):\n","    # loop on fitters\n","    for i, key in enumerate(fitters):\n","        fig, axes = plt.subplots(1, 1, figsize=(15, 8))\n","        axes.set_title('{} {}'.format(desc, key))\n","        # loop on labels\n","        for j, label in enumerate(np.unique(labels)):\n","            idx = (labels == label)\n","            unique, counts = np.unique(idx, return_counts=True)\n","            if counts[unique==True] > n_min:\n","                fitters[key].fit(times[idx], events[idx], label='label {}'.format(label))\n","                fitters[key].plot_survival_function(ax=axes, ci_show=False)\n","        axes.grid()\n","        plt.savefig(results_path/'{}_{}_lifelines.png'.format(key, desc))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Example from EUROMDS\n","figure = plt.figure(figsize=(20, 4),\n","                    facecolor='white',)\n","j = 0\n","idx = np.random.permutation(len(x))\n","xx = x[idx, :]\n","\n","for example in xx[:10]:\n","  plt.subplot(2, 5, j+1)\n","  plt.imshow(example.reshape(img_shape), cmap='gray', aspect='equal')\n","  plt.axis('off')\n","  j += 1\n","plt.savefig(results_path/'original_data.png',\n","            facecolor=fig.get_facecolor(),\n","            edgecolor='none')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Example from EUROMDS from pretrained autoencoder\n","encoder.set_weights(encoder_param)\n","figure = plt.figure(figsize=(20, 4),\n","                    facecolor='white',)\n","j = 0\n","\n","for example in autoencoder(xx[:10]).numpy():\n","  plt.subplot(2, 5, j+1)\n","  plt.imshow(example.reshape(img_shape), cmap='gray', aspect='equal')\n","  plt.axis('off')\n","  j += 1\n","plt.savefig(results_path/'pretrain_ae_data.png',\n","            facecolor=fig.get_facecolor(),\n","            edgecolor='none')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Example from EUROMDS from finetuned autoencoder\n","encoder.set_weights(encoder_ft_param)\n","figure = plt.figure(figsize=(20, 4),\n","                    facecolor='white',)\n","j = 0\n","\n","for example in autoencoder(xx[:10]).numpy():\n","  plt.subplot(2, 5, j+1)\n","  plt.imshow(example.reshape(img_shape), cmap='gray', aspect='equal')\n","  plt.axis('off')\n","  j += 1\n","plt.savefig(results_path/'finetune_ae_data.png',\n","            facecolor=fig.get_facecolor(),\n","            edgecolor='none')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Example from EUROMDS from final model\n","encoder.set_weights(encoder_final_param)\n","figure = plt.figure(figsize=(20, 4),\n","                    facecolor='white',)\n","j = 0\n","\n","for example in autoencoder(xx[:10]).numpy():\n","  plt.subplot(2, 5, j+1)\n","  plt.imshow(example.reshape(img_shape), cmap='gray', aspect='equal')\n","  plt.axis('off')\n","  j += 1\n","plt.savefig(results_path/'cluster_ae_data.png',\n","            facecolor=fig.get_facecolor(),\n","            edgecolor='none')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"24f6449c2766f597e442bf0c6b08f70e85c443f010de0cdb87db978cb9e1ec44"},"kernelspec":{"display_name":"Python 3.9.5 64-bit ('uni-env': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
